<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<!-- Mirrored from ismir2009.ismir.net/tutorials.html by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 23 Jan 2014 06:01:23 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<!--<base href="http://ismir2009.ismir.net/">-->
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>ISMIR 2009 - 10th International Society for Music Information Retrieval Conference</title>
<link href="ismir2009.css" rel="stylesheet" type="text/css" />
</head>

<body>
<div id="container">
  <div id="header">
    <h1>10th International Society for Music Information Retrieval Conference</h1>
    <h3>Kobe, Japan</h3>
    <h3>October 26-30, 2009</h3>
  </div>
  <div id="header2">
  </div>


  <div id="navibar">
      <ul>
        <li><a href="index-2.html">HOME</a></li>
        <li><a href="cfp.html">Call for Papers</a></li>
        <li><a href="submission.html">Submission</a></li>
        <li><a href="presenters.html">Information for Presenters</a></li>
        <li><a href="program.html">Program</a></li>
        <li><a href="tutorials.html">Tutorials</a></li>
        <li><a href="invited.html">Invited Presentations</a></li>
        <li><a href="http://www.columbia.edu/~tb2332/fmir/" target="_blank">Special Session: f(MIR)</a></li>
        <li><a href="http://www.music-ir.org/mirex/2009/index.php/Main_Page" target="_blank">MIREX 2009</a></li>
        <li><a href="registration.html">Registration</a></li>
        <li><a href="venue.html">Conference Venue</a></li>
        <li><a href="accommodation.html">Accommodation</a></li>
        <li><a href="access.html">Access</a></li>
        <li><a href="social.html">Social Program</a></li>
        <li><a href="music.html">Music Performances</a></li>
        <li><a href="events.html">Satellite Events</a></li>
        <li><a href="support.html">Corporate Support</a></li>
        <li><a href="committee.html">Conference Committee</a></li>
        <li><a href="links.html">ISMIR Links</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
      <img src="images/ismirlogo.png" alt="ISMIR" width="180" height="73" />
  </div>


  <!--mainleft-->
  <div id="maincontent">

      <h1>Tutorials</h1>
<!--
        <div class="attention">
          Tutorial Proposal deadline: January 31, 2009
        </div>
        <div class="border"></div>
-->
<div class="paragraph">
The first day of the conference (October 26, Monday) will consist of
a parallel session of tutorials.
</div>

<h3>Morning Tutorials:</h3>
<div class="paragraph">
<ul>
<li>Tutorial AM 1: <a href="#am1">MIR at the Scale of the Web</a></li>
<li>Tutorial AM 2: <a href="#am2">Mining the Social Web for Music-Related Data: A Hands-on Tutorial</a></li>
</ul>
</div>
<h3>Afternoon Tutorials:</h3>
<div class="paragraph">
<ul>
<li>Tutorial PM 1: <a href="#pm1">Using Visualizations for Music Discovery</a></li>
<li>Tutorial PM 2: <a href="#pm2">Share and Share Alike, You Can Say Anything about Music in the Web of Data</a></li>
</ul>
</div>

<div class="border"></div>
<h2 id="am1">Tutorial AM 1 (10:00-13:00): MIR at the Scale of the Web</h2>
<h3>by Malcolm Slaney (Yahoo! Research), and Michael Casey (Dartmouth College and University of London)</h3>
<div class="paragraph">
Contact: malcolm [at] ieee.org
</div>
<h3>Abstract</h3>
<div class="paragraph">
In the last couple of years we have received access to music databases with 
millions of songs. This massive change in the amount of data available to 
researchers is changing the face of MIR. In many domains, speech-recognition is 
most notable, people have observed that the best way to improve their 
algorithm's performance is to add more data. Starting with hidden-Markov models 
(HMMs) and support-vector machines, people have applied ever greater amounts of 
data to their problems and been rewarded with new levels of performance.
What are the algorithms and ideas that are necessary to work with such large 
databases? How do we define the scope of a problem, and how do we apply modern 
clusters of processors to these problems? What does it take to collect, manage 
and deliver solutions with millions of songs and terabytes of data?
In this tutorial we will talk about a range of algorithms and tools that make 
it easy/easier to scale our work to Internet-sized collections of music. The 
field is just developing so this tutorial will talk about a range of techniques 
that are in use today. Millions of songs fit into a small number of terabytes, 
which is just a few hundred dollars of disk space. This tutorial will give 
attendees the tools they need to make use of this data. This tutorial will give 
attendees an overview and pointers to the tools that will allow them to scale 
their work to modern datasets. The tutorial will discuss the theoretical and
practical problem with large data, applications where large amounts of data are 
important to consider, types of algorithms that are practical with such large 
datasets, and examples of implementation techniques that make these algorithms 
practical. The tutorial will be illustrated with many real-world examples and 
results.
</div>
<h3>Biographies of the Presenters</h3>
<div class="paragraph">
Dr. Malcolm Slaney is a principal scientist at Yahoo! Research. There he has been
working on music- and image-retrieval algorithms in databases with billions of 
items. He is a senior member of the IEEE and an Associate Editor of IEEE 
Transactions on Audio, Speech and Signal Processing. He has given successful 
tutorials at ICASSP 1996 and 2009 on "Applications of Psychoacoustics to Signal 
Processing" and on "Multimedia Information Retrieval" at SIGIR and ICASSP. 
He is a (consulting) Professor at Stanford CCRMA where he has led the Hearing 
Seminar for the last 18 years.
</div>
<div class="paragraph">
Michael Casey is Professor of Music and director of the graduate program in Digital
Music at Dartmouth College, USA, and Professor of Computer Science at Goldsmiths,
University of London, UK. He received his Ph.D. from the MIT Media Laboratory in
1998 in the fields of statistical audio. His recent activities include forming the 
OMRAS2 (Online Music Recognition and Searching) group at Goldsmiths, for which he 
served as Principal Investigator, and co-authoring AudioDB: an open-source, 
multimedia search engine that scales to billions of items.
</div>
<div class="border"></div>
<h2 id="am2">Tutorial AM 2 (10:00-13:00): Mining the Social Web for Music-Related Data: A Hands-on Tutorial</h2>
<h3>by Claudio Baccigalupo (Spanish Council for Scientific Research), and Ben Fields (University of London)</h3>
<div class="paragraph">
The Tutorial Website: <a href="http://ismir2009.benfields.net/" target="_blank">http://ismir2009.benfields.net</a> (external link)
</div>
<h3>Abstract</h3>
<div class="paragraph">
The social web is a useful resource for those conducting research in music informatics.
Yet there exists no "standard" way to integrate web-based data with other more common signal-based music informatics methods.
In this tutorial we go through the entire process of retrieving and leveraging data from the social web for MIR tasks.
This is done through the use of hands-on examples intended to introduce the larger ISMIR community to web-mining techniques. 
</div>
<div class="paragraph">
The intended audience is formed of people who are familiar with other MIR techniques (principally content-based)
and who can benefit from knowledge available on the web to improve their algorithms and evaluation processes.
The tutorial presents a series of short snippets of code to rapidly retrieve musical information
from the web in the form of genre-labelled audio excerpts, tags, lyrics, social experiences,
acoustic analyses or similarity measures for millions of songs.
More information about the tutorial can be found at <a href="http://ismir2009.benfields.net/" target="_blank">http://ismir2009.benfields.net</a>.
</div>
<h3>Biographies of the Presenters</h3>
<div class="paragraph">
Claudio Baccigalupo is a PhD candidate at the Artificial Intelligence Research Institute (IIIA-CSIC),
with the thesis discussion expected in November 2009. He holds a 5-year degree in Computer Technology
with top marks and distinction. His research focuses on recommender systems in a musical context:
he investigated how to extract musical knowledge from the analysis of playlists and how to customise radio channels for groups of listeners. 
</div>
<div class="paragraph">
Benjamin Fields is a PhD candidate with the Intelligent Sound and Music Systems (ISMS) research group at the Department of Computing,
Goldsmiths, University of London, with his dissertation submission anticipated in late spring 2010.
His current research centers on applications to understand and exploit the semantic gap
between the social relationships of artists and the acoustic similarity of works these artists produce. 
</div>
<div class="border"></div>
<h2 id="pm1">Tutorial PM 1 (14:30-17:30): Using Visualizations for Music Discovery</h2>
<h3>by Justin Donaldson (Indiana University), and Paul Lamere (The Echo Nest)</h3>
<div class="paragraph">
The Tutorial Website: <a href="http://musicviz.googlepages.com/home" target="_blank">http://musicviz.googlepages.com/home</a> (external link)
</div>
<h3>Abstract</h3>
<div class="paragraph">
As the world of online music grows, tools for helping people find new and 
interesting music in these extremely large collections become increasingly 
important. In this tutorial we look at one such tool that can be used to help 
people explore large music collections: information visualization. We survey
the state-of-the-art in visualization for music discovery in commercial and 
research systems. Using numerous examples, we explore different algorithms and 
techniques that can be used to visualize large and complex music spaces,
focusing on the advantages and the disadvantages of the various techniques. We 
investigate user factors that affect the usefulness of a visualization and we 
suggest possible areas of exploration for future research.
</div>
<h3>Biographies of the Presenters</h3>
<div class="paragraph">
Justin Donaldson is a PhD candidate at Indiana University School of Informatics, 
as well as a regular research intern at Strands, Inc. Justin is interested with 
the analyses and visualizations of social sources of data, such as those that 
are generated from playlists, blogs, and bookmarks.
</div>
<div class="paragraph">
Paul Lamere is the Director of Developer Community at The Echo Nest, a
research-focused music intelligence startup that provides music information
services to developers and partners through a data mining and machine
listening platform. Paul is especially interested in hybrid music
recommenders and using visualizations to aid music discovery.
</div>
<div class="border"></div>
<h2 id="pm2">Tutorial PM 2 (14:30-17:30): Share and Share Alike, You Can Say Anything about Music in the Web of Data</h2>
<h3>by Kurt Jacobson (University of London), Yves Raimond (BBC), Gyorgy Fazekas (University of London), and Michael Smethurst (BBC)</h3>
<div class="paragraph">
The Tutorial Website: <a href="http://ismir2009.dbtune.org/" target="_blank">http://ismir2009.dbtune.org/</a> (external link)
</div>
<h3>Abstract</h3>
<div class="paragraph">
Linked Data provides a powerful framework for the expression and
re-use of structured data. Recent efforts have brought this powerful 
framework to bear on the field of music informatics. This tutorial 
will provide an introduction to Linked Data concepts and how and why 
they should be used in the context of music-related studies. Using 
practical examples we will explore what data sets are already available
and how they can be used to answer questions about music. We will also
explore how signal processing tools and results can be described as 
structured data. Finally, we will demonstrate tools and best practice 
for researchers who wish to publish their own data sets on the Semantic
Web in a Linked Data fashion.
</div>
<h3>Biographies of the Presenters</h3>
<div class="paragraph">
Kurt Jacobson is a PhD candidate at the Centre for Digital Music. As 
assistant administrator of DBTune.org he has worked to create Semantic Web
services for music including a service publishing structured data about music
artists on Myspace and musicological data about classical music composers. He
is working on modeling and exploring connections in music using structured data
from heterogeneous sources including historical musicology, social networks, and
audio analysis.
</div>
<div class="paragraph"> 
Yves Raimond is a Software Engineer at BBC Audio & Music interactive,
after completing a PhD at the Centre for Digital Music, Queen Mary, University
of London. He is one of the editors of the Music Ontology specification, and
the creator and head administrator of the DBTune.org service, publishing a
wide variety of structured music-related data. He is now working on 
<a href="http://www.bbc.co.uk/programmes" target="_blank">http://www.bbc.co.uk/programmes</a>, publishing a wide range of structured data 
about BBC programmes. He also maintains the DBTune blog.
</div>
<div class="paragraph"> 
Gyorgy Fazekas is a PhD candidate at the Centre for Digital Music. His main
research interest includes the development of semantic audio technologies and
their application to creative music production. He is working on ontology based
information management for audio applications.
</div>
<div class="paragraph"> 
Michael Smethurst is an Information Architect at BBC Audio & Music. He
is currently working on BBC Programmes, BBC Music and BBC Events, publishing 
and interlinking data in a number of overlapping domains. He writes on
the BBC Radio Labs blog about Linked Data and web publishing.
</div>
<div class="border"></div>

  </div>
  <!--baseLeft-->






  <div id="footer">
    <p>Copyright (C) 2009 ISMIR 2009. All Rights Reserved.
    </p>
  </div>
</div>
</body>

<!-- Mirrored from ismir2009.ismir.net/tutorials.html by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 23 Jan 2014 06:01:23 GMT -->
</html>
